{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist \n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(-1, 28,28, 1)\n",
    "test_X = test_X.reshape(-1, 28,28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255\n",
    "test_X = test_X / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 140,682\n",
      "Trainable params: 140,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.6643 - accuracy: 0.7601\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.3242 - accuracy: 0.8823\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.2794 - accuracy: 0.8975\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.2458 - accuracy: 0.9110\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.2214 - accuracy: 0.9196\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 32s 34ms/step - loss: 0.2143 - accuracy: 0.9216\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.1955 - accuracy: 0.9283\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.1785 - accuracy: 0.9338\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1670 - accuracy: 0.9393\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1515 - accuracy: 0.9450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff53a0c29d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2609 - accuracy: 0.9082\n",
      "Test loss 0.2608666718006134\n",
      "Test accuracy 0.9082000255584717\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_X, test_Y_one_hot)\n",
    "print('Test loss', loss)\n",
    "print('Test accuracy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ohe = model.predict(test_X)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=test_Y, y_pred=y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[835,   0,  26,  30,  14,   1,  91,   0,   2,   1],\n",
       "       [  4, 976,   1,  15,   2,   0,   2,   0,   0,   0],\n",
       "       [ 12,   0, 874,   8,  63,   0,  42,   0,   1,   0],\n",
       "       [ 11,   1,  15, 931,  21,   1,  19,   0,   1,   0],\n",
       "       [  2,   0,  43,  32, 891,   0,  32,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 985,   0,  14,   0,   1],\n",
       "       [111,   1,  81,  34,  80,   1, 687,   0,   5,   0],\n",
       "       [  0,   0,   0,   0,   0,   8,   0, 969,   0,  23],\n",
       "       [  1,   0,   3,   5,   6,   6,   4,   4, 971,   0],\n",
       "       [  1,   0,   0,   0,   0,  12,   0,  24,   0, 963]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.4))\n",
    "\n",
    "model_2.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.4))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(128, activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.4))\n",
    "model_2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 327,242\n",
      "Trainable params: 326,410\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 108s 115ms/step - loss: 0.8200 - accuracy: 0.7174\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 111s 118ms/step - loss: 0.3709 - accuracy: 0.8675\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 111s 119ms/step - loss: 0.3131 - accuracy: 0.8875\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 128s 137ms/step - loss: 0.2780 - accuracy: 0.9009\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 124s 132ms/step - loss: 0.2584 - accuracy: 0.9066\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 115s 122ms/step - loss: 0.2425 - accuracy: 0.9134\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 126s 134ms/step - loss: 0.2278 - accuracy: 0.9182\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2092 - accuracy: 0.9250\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 117s 125ms/step - loss: 0.2030 - accuracy: 0.9286\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 128s 137ms/step - loss: 0.1895 - accuracy: 0.9297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff53b1bb940>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_X, train_Y_one_hot, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2277 - accuracy: 0.9179\n",
      "Test loss 0.2277098149061203\n",
      "Test accuracy 0.917900025844574\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_2.evaluate(test_X, test_Y_one_hot)\n",
    "print('Test loss', loss)\n",
    "print('Test accuracy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ohe_2 = model_2.predict(test_X)\n",
    "y_pred_labels_2 = np.argmax(y_pred_ohe_2, axis=1)\n",
    "confusion_matrix_2 = metrics.confusion_matrix(y_true=test_Y, y_pred=y_pred_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[823,   0,   7,  18,   2,   2, 145,   0,   3,   0],\n",
       "       [  0, 983,   0,  14,   0,   0,   1,   0,   2,   0],\n",
       "       [ 13,   1, 806,  10,  92,   0,  78,   0,   0,   0],\n",
       "       [  3,   0,   3, 939,  27,   0,  28,   0,   0,   0],\n",
       "       [  0,   0,  17,  17, 911,   0,  55,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 977,   0,  12,   0,  11],\n",
       "       [ 51,   0,  29,  28,  62,   0, 826,   0,   4,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0, 961,   0,  36],\n",
       "       [  4,   1,   0,   7,   4,   1,   7,   3, 973,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0,  16,   0, 980]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
